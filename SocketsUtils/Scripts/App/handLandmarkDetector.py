import cv2
import mediapipe as mp
import json
import socket
import time

class HandTracker:
    def __init__(self, cameraDeviceID=0, showCamera=True):
        """
        Hand Tracker com MediaPipe + envio UDP dos landmarks.
        
        Args:
            cameraDeviceID: ID da c√¢mera
            showCamera: Mostrar janela de debug
        """
        print("=" * 60)
        print("üñêÔ∏è  HAND TRACKER - MediaPipe + UDP")
        print("=" * 60)
        
        self.deviceCamID = cameraDeviceID
        self.debugCamera = showCamera
        
        # Inicializa MediaPipe Hands
        print("\nü§ñ Inicializando MediaPipe...")
        self.mp_hands = mp.solutions.hands
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        # Configura√ß√µes do detector
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,              # Detecta at√© 2 m√£os
            min_detection_confidence=0.7,  # Confian√ßa m√≠nima para detec√ß√£o
            min_tracking_confidence=0.5    # Confian√ßa m√≠nima para tracking
        )
        
        print("‚úÖ MediaPipe Hands inicializado")
        print(f"   ‚Ä¢ M√°ximo de m√£os: 2")
        print(f"   ‚Ä¢ Confian√ßa de detec√ß√£o: 0.7")
        print(f"   ‚Ä¢ Confian√ßa de tracking: 0.5")
        
        # Socket UDP para enviar landmarks
        print("\nüîå Configurando UDP...")
        self.udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.server_ip = "127.0.0.1"
        self.server_port = 8384  # Porta diferente do v√≠deo
        
        print(f"‚úÖ UDP configurado: {self.server_ip}:{self.server_port}")
        
        # Estat√≠sticas
        self.frame_count = 0
        self.hands_detected_count = 0
        self.packets_sent = 0
        
    def process_hands(self, frame):
        """
        Processa frame e detecta m√£os.
        
        Returns:
            tuple: (frame_anotado, dados_json)
        """
        # Converte BGR para RGB (MediaPipe usa RGB)
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Processa frame
        results = self.hands.process(frame_rgb)
        
        # Prepara dados para enviar
        hands_data = {
            "timestamp": time.time(),
            "frame_number": self.frame_count,
            "hands_detected": 0,
            "hands": []
        }
        
        # Se detectou m√£os
        if results.multi_hand_landmarks:
            hands_data["hands_detected"] = len(results.multi_hand_landmarks)
            self.hands_detected_count += 1
            
            # Para cada m√£o detectada
            for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                # Pega informa√ß√£o sobre qual m√£o (esquerda/direita)
                handedness = results.multi_handedness[hand_idx].classification[0]
                hand_label = handedness.label  # "Left" ou "Right"
                hand_score = handedness.score
                
                # Extrai landmarks (21 pontos)
                landmarks = []
                for landmark in hand_landmarks.landmark:
                    landmarks.append({
                        "x": landmark.x,      # Normalizado 0-1
                        "y": landmark.y,      # Normalizado 0-1
                        "z": landmark.z,      # Profundidade relativa
                        "visibility": landmark.visibility
                    })
                
                # Adiciona m√£o aos dados
                hands_data["hands"].append({
                    "hand_index": hand_idx,
                    "label": hand_label,
                    "confidence": hand_score,
                    "landmarks": landmarks
                })
                
                # Desenha landmarks no frame (para debug)
                if self.debugCamera:
                    self.mp_drawing.draw_landmarks(
                        frame,
                        hand_landmarks,
                        self.mp_hands.HAND_CONNECTIONS,
                        self.mp_drawing_styles.get_default_hand_landmarks_style(),
                        self.mp_drawing_styles.get_default_hand_connections_style()
                    )
                    
                    # Adiciona texto com label da m√£o
                    h, w, _ = frame.shape
                    cx = int(hand_landmarks.landmark[0].x * w)
                    cy = int(hand_landmarks.landmark[0].y * h)
                    cv2.putText(frame, f"{hand_label} ({hand_score:.2f})", 
                               (cx - 50, cy - 20),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, 
                               (0, 255, 0), 2)
        
        return frame, hands_data
    
    def send_hand_data(self, hands_data):
        """
        Envia dados das m√£os via UDP (JSON).
        
        Args:
            hands_data: Dicion√°rio com dados das m√£os
            
        Returns:
            bool: True se enviado com sucesso
        """
        try:
            # Converte para JSON
            json_data = json.dumps(hands_data)
            json_bytes = json_data.encode('utf-8')
            
            # Verifica tamanho (UDP tem limite)
            if len(json_bytes) > 60000:
                print(f"‚ö†Ô∏è Dados muito grandes: {len(json_bytes)} bytes")
                return False
            
            # Envia via UDP
            self.udp_socket.sendto(json_bytes, (self.server_ip, self.server_port))
            self.packets_sent += 1
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao enviar dados: {e}")
            return False
    
    def run(self):
        """Inicia o loop de captura e detec√ß√£o."""
        print(f"\nüì∑ Abrindo c√¢mera {self.deviceCamID}...")
        
        # Abre c√¢mera
        cap = cv2.VideoCapture(self.deviceCamID, cv2.CAP_DSHOW)
        
        if not cap.isOpened():
            print("‚ùå ERRO: N√£o foi poss√≠vel abrir a c√¢mera!")
            return
        
        # Configura√ß√µes
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"‚úÖ C√¢mera aberta: {width}x{height}")
        print(f"\n{'='*60}")
        print("üöÄ INICIANDO DETEC√á√ÉO DE M√ÉOS")
        print("‚è∏Ô∏è  Pressione ESC para parar")
        print("üìä Estat√≠sticas a cada 30 frames")
        print(f"{'='*60}\n")
        
        start_time = time.time()
        
        try:
            while cap.isOpened():
                ret, frame = cap.read()
                
                if not ret:
                    print("‚ö†Ô∏è Falha ao capturar frame")
                    break
                
                self.frame_count += 1
                
                # Processa m√£os
                annotated_frame, hands_data = self.process_hands(frame)
                
                # Envia dados via UDP
                self.send_hand_data(hands_data)
                
                # Estat√≠sticas a cada 30 frames
                if self.frame_count % 30 == 0:
                    elapsed = time.time() - start_time
                    fps = self.frame_count / elapsed if elapsed > 0 else 0
                    detection_rate = (self.hands_detected_count / self.frame_count * 100) if self.frame_count > 0 else 0
                    
                    print(f"üìä Frames: {self.frame_count} | "
                          f"Detec√ß√µes: {self.hands_detected_count} | "
                          f"Taxa: {detection_rate:.1f}% | "
                          f"FPS: {fps:.1f} | "
                          f"Pacotes: {self.packets_sent}")
                
                # Mostra janela de debug
                if self.debugCamera:
                    # Adiciona informa√ß√µes na tela
                    info_frame = annotated_frame.copy()
                    cv2.putText(info_frame, f"Frames: {self.frame_count}", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(info_frame, f"Maos detectadas: {hands_data['hands_detected']}", 
                               (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    cv2.imshow('Hand Tracking - Pressione ESC', info_frame)
                    
                    if cv2.waitKey(1) & 0xFF == 27:  # ESC
                        print("\n‚èπÔ∏è  ESC pressionado - Encerrando...")
                        break
                        
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è  Interrompido (Ctrl+C)")
            
        except Exception as e:
            print(f"\n‚ùå ERRO: {e}")
            import traceback
            traceback.print_exc()
            
        finally:
            # Cleanup
            print("\n" + "=" * 60)
            print("üßπ LIMPANDO RECURSOS")
            print("=" * 60)
            
            cap.release()
            cv2.destroyAllWindows()
            self.hands.close()
            self.udp_socket.close()
            
            # Estat√≠sticas finais
            print(f"\nüìà ESTAT√çSTICAS FINAIS:")
            print(f"   ‚Ä¢ Total de frames: {self.frame_count}")
            print(f"   ‚Ä¢ Frames com m√£os detectadas: {self.hands_detected_count}")
            print(f"   ‚Ä¢ Pacotes UDP enviados: {self.packets_sent}")
            
            if self.frame_count > 0:
                detection_rate = (self.hands_detected_count / self.frame_count * 100)
                print(f"   ‚Ä¢ Taxa de detec√ß√£o: {detection_rate:.1f}%")
            
            print("\n‚úÖ Programa encerrado\n")


# Execu√ß√£o
if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("HAND TRACKING - MediaPipe + UDP Sender")
    print("=" * 60 + "\n")
    
    try:
        tracker = HandTracker(cameraDeviceID=0, showCamera=True)
        tracker.run()
        
    except Exception as e:
        print(f"\n‚ùå ERRO FATAL: {e}")
        import traceback
        traceback.print_exc()
